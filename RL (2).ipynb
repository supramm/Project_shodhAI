{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b4748a3",
   "metadata": {},
   "source": [
    "# Offline RL for Loan Approval (Contextual Bandit)\n",
    "\n",
    "This notebook frames loan approval as an **offline RL / contextual bandit** problem and trains a simple offline agent using **Fitted Q / supervised regression**. It treats each loan application as a single-step decision (approve or deny). The notebook is intentionally standalone: it loads a CSV, preprocesses features, engineers rewards according to your specification, trains per-action regressors to estimate Q(s,a), derives a policy `pi(s)=argmax_a Q(s,a)`, evaluates on a holdout test set, and saves the trained models.\n",
    "\n",
    "**Reward design (per your spec):**\n",
    "- If action == 0 (Deny): reward = 0\n",
    "- If action == 1 (Approve) and loan was fully paid: reward = + (loan_amnt * int_rate)\n",
    "- If action == 1 (Approve) and loan defaulted: reward = - loan_amnt\n",
    "\n",
    "---\n",
    "\n",
    "**How to use:**\n",
    "1. Upload a CSV dataset containing loan records (common columns used: `loan_amnt`, `int_rate`, `loan_status` or `fully_paid` or `is_default`).\n",
    "2. Update the `COLUMN_MAPPING` cell below if your column names differ.\n",
    "3. Run all cells. The notebook will produce `outputs/` with models and metrics.\n",
    "\n",
    "This is intentionally simple and reproducible; for production-grade offline RL you would use specialized libraries (CQL, BCQ, CRR, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & helper functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "def infer_boolean_fully_paid(df):\n",
    "    \"\"\"Try to infer a boolean fully-paid column from common loan_status values.\"\"\"\n",
    "    # Common values: 'Fully Paid', 'Charged Off', 'Default', 'Current', 'Late'\n",
    "    if 'loan_status' in df.columns:\n",
    "        col = df['loan_status'].astype(str).str.lower()\n",
    "        fully = col.isin(['fully paid', 'fully_paid', 'paid', 'paid off']) | col.str.contains('fully paid')\n",
    "        default = col.isin(['charged off', 'default', 'charged_off']) | col.str.contains('charged')\n",
    "        res = pd.Series(np.nan, index=df.index)\n",
    "        res[fully] = True\n",
    "        res[default] = False\n",
    "        return res\n",
    "    # try other columns\n",
    "    for candidate in ['fully_paid', 'is_default', 'default_flag', 'repaid']:\n",
    "        if candidate in df.columns:\n",
    "            col = df[candidate]\n",
    "            return col.astype('bool')\n",
    "    return None\n",
    "\n",
    "def compute_reward(row, loan_amnt_col='loan_amnt', int_rate_col='int_rate', fully_paid_col='fully_paid'):\n",
    "    \"\"\"Compute reward for a single row using the provided column names and the problem's reward design.\"\"\"\n",
    "    loan_amnt = float(row[loan_amnt_col])\n",
    "    int_rate = float(row[int_rate_col])\n",
    "    fully = row[fully_paid_col]\n",
    "    if isinstance(int_rate, str) and '%' in int_rate:\n",
    "        int_rate = float(int_rate.replace('%','')) / 100.0\n",
    "    if int_rate > 1.0:\n",
    "        int_rate = int_rate / 100.0\n",
    "    return {'approve_reward': (loan_amnt * int_rate) if fully else (-loan_amnt),\n",
    "            'deny_reward': 0.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e70149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === USER: Set your CSV path and column mapping here ===\n",
    "CSV_PATH = 'loan_data.csv'  # <-- change to your uploaded CSV filename\n",
    "COLUMN_MAPPING = {\n",
    "    'loan_amnt': 'loan_amnt',   # principal\n",
    "    'int_rate': 'int_rate',     # interest rate (float or percent string)\n",
    "    'loan_status': 'loan_status' # column used to infer fully paid vs default\n",
    "}\n",
    "fully_paid_col_override = None  # e.g., 'fully_paid' or None to infer from loan_status\n",
    "\n",
    "import os\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    print(f\"Warning: CSV_PATH '{CSV_PATH}' not found in working directory. Upload your CSV or update the path.\") \n",
    "else:\n",
    "    print('CSV found:', CSV_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f2c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data, infer outcome (fully paid), and compute rewards\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print('Loaded rows:', len(df))\n",
    "print('Columns:', list(df.columns)[:50])\n",
    "\n",
    "if fully_paid_col_override and fully_paid_col_override in df.columns:\n",
    "    df['fully_paid'] = df[fully_paid_col_override].astype(bool)\n",
    "else:\n",
    "    inferred = infer_boolean_fully_paid(df)\n",
    "    if inferred is not None:\n",
    "        df['fully_paid'] = inferred\n",
    "    else:\n",
    "        raise ValueError('Could not infer fully_paid outcome from dataset. Please set fully_paid_col_override to the appropriate column name.')\n",
    "\n",
    "missing_outcome = df['fully_paid'].isna().sum()\n",
    "if missing_outcome > 0:\n",
    "    print(f'Warning: {missing_outcome} rows have unknown outcome; dropping them.')\n",
    "    df = df[~df['fully_paid'].isna()].copy()\n",
    "\n",
    "for key, col in COLUMN_MAPPING.items():\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Expected column '{col}' for mapping key '{key}' not found in CSV. Update COLUMN_MAPPING.\")\n",
    "\n",
    "loan_amnt_col = COLUMN_MAPPING['loan_amnt']\n",
    "int_rate_col = COLUMN_MAPPING['int_rate']\n",
    "\n",
    "rewards = df.apply(lambda r: compute_reward(r, loan_amnt_col=loan_amnt_col, int_rate_col=int_rate_col, fully_paid_col='fully_paid'), axis=1)\n",
    "df['approve_reward'] = [x['approve_reward'] for x in rewards]\n",
    "df['deny_reward'] = 0.0\n",
    "\n",
    "observed_action_col = None  # e.g., 'was_approved' or 'policy_action' - set to None if unknown\n",
    "if observed_action_col and observed_action_col in df.columns:\n",
    "    df['observed_action'] = df[observed_action_col].astype(int)\n",
    "else:\n",
    "    df['observed_action'] = np.nan\n",
    "\n",
    "print('Prepared dataset with computed rewards. Sample:')\n",
    "display(df.head().T.iloc[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b63cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features automatically: drop target and outcome columns\n",
    "exclude_cols = ['approve_reward', 'deny_reward', 'fully_paid', 'observed_action']\n",
    "feature_cols = [c for c in df.columns if c not in exclude_cols and c not in [loan_amnt_col, int_rate_col]]\n",
    "feature_cols = [loan_amnt_col, int_rate_col] + [c for c in feature_cols if c not in (loan_amnt_col, int_rate_col)]\n",
    "print('Using feature columns (first 30):', feature_cols[:30])\n",
    "\n",
    "num_cols = df[feature_cols].select_dtypes(include=['int64','float64','int32','float32']).columns.tolist()\n",
    "cat_cols = [c for c in feature_cols if c not in num_cols]\n",
    "\n",
    "print('Numeric cols:', num_cols)\n",
    "print('Categorical cols:', cat_cols)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ], remainder='drop')\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y_approve = df['approve_reward'].values\n",
    "y_deny = df['deny_reward'].values\n",
    "\n",
    "X_trans = preprocessor.fit_transform(X)\n",
    "print('Transformed feature shape:', X_trans.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train regressors to estimate Q(s,a) for each action (0: deny, 1: approve)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "X_train, X_test, y1_train, y1_test, y0_train, y0_test = train_test_split(X_trans, y_approve, y_deny, test_size=0.2, random_state=42)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "\n",
    "model_approve = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model_deny = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "\n",
    "model_approve.fit(X_train, y1_train)\n",
    "model_deny.fit(X_train, y0_train)\n",
    "\n",
    "joblib.dump(model_approve, 'outputs/model_approve.pkl')\n",
    "joblib.dump(model_deny, 'outputs/model_deny.pkl')\n",
    "joblib.dump(preprocessor, 'outputs/preprocessor.pkl')\n",
    "\n",
    "print('Models trained and saved to outputs/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ece59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive deterministic policy pi(s) = argmax_a Q_hat(s,a) and evaluate on test set\n",
    "from sklearn.model_selection import train_test_split as tts2\n",
    "q1_test = model_approve.predict(X_test)\n",
    "q0_test = model_deny.predict(X_test)\n",
    "policy_actions = (q1_test > q0_test).astype(int)\n",
    "\n",
    "indices = np.arange(X_trans.shape[0])\n",
    "_, test_idx = tts2(indices, test_size=0.2, random_state=42)\n",
    "df_test = df.iloc[test_idx].copy().reset_index(drop=True)\n",
    "\n",
    "df_test['policy_action'] = policy_actions.tolist()\n",
    "df_test['policy_reward'] = df_test.apply(lambda r: r['approve_reward'] if r['policy_action']==1 else 0.0, axis=1)\n",
    "\n",
    "if df_test['observed_action'].notna().any():\n",
    "    df_test['behavior_reward'] = df_test.apply(lambda r: r['approve_reward'] if r['observed_action']==1 else 0.0, axis=1)\n",
    "else:\n",
    "    df_test['behavior_reward'] = np.nan\n",
    "\n",
    "policy_total_reward = df_test['policy_reward'].sum()\n",
    "policy_avg_reward = df_test['policy_reward'].mean()\n",
    "behavior_total_reward = df_test['behavior_reward'].sum() if df_test['behavior_reward'].notna().any() else np.nan\n",
    "\n",
    "print(f\"Policy total reward on test set: {policy_total_reward:.2f}\")\n",
    "print(f\"Policy average reward per-applicant: {policy_avg_reward:.4f}\")\n",
    "if not np.isnan(behavior_total_reward):\n",
    "    print(f\"Observed behavior total reward on test set: {behavior_total_reward:.2f}\")\n",
    "print('Policy approval rate (fraction approved):', df_test['policy_action'].mean())\n",
    "\n",
    "approved = df_test[df_test['policy_action']==1]\n",
    "if len(approved) > 0:\n",
    "    frac_fully = approved['fully_paid'].mean()\n",
    "    print('Fraction of policy-approved applicants who truly repaid:', frac_fully)\n",
    "else:\n",
    "    print('Policy approved zero applicants on test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d839c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a quick policy wrapper that loads preprocessor and models and returns actions for a DataFrame of applicants\n",
    "policy_code = '''import joblib, numpy as np, pandas as pd\n",
    "pre = joblib.load('outputs/preprocessor.pkl')\n",
    "m1 = joblib.load('outputs/model_approve.pkl')\n",
    "m0 = joblib.load('outputs/model_deny.pkl')\n",
    "def policy_from_df(df, feature_cols):\n",
    "    X = df[feature_cols].copy()\n",
    "    X_trans = pre.transform(X)\n",
    "    q1 = m1.predict(X_trans)\n",
    "    q0 = m0.predict(X_trans)\n",
    "    actions = (q1 > q0).astype(int)\n",
    "    return actions\n",
    "'''\n",
    "with open('outputs/policy_wrapper.py', 'w') as f:\n",
    "    f.write(policy_code)\n",
    "print('Saved outputs/policy_wrapper.py')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
